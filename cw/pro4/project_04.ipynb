{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import cv2 as cv\n",
    "\n",
    "# from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "# from keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256, 256)\n",
    "data_dir = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input shape and number of classes\n",
    "input_shape = (256, 256)\n",
    "num_classes = 4\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(rescale=1.0 / 255, validation_split=0.2)\n",
    "\n",
    "# Load images and labels from directories\n",
    "train_ds = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=input_shape,\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",  # This ensures labels are one-hot encoded\n",
    "    subset=\"training\",\n",
    ")\n",
    "\n",
    "val_ds = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=input_shape,\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_save_model(save_path: str, epochs: int = 5) -> None:\n",
    "    data_dir = \"./data/\"\n",
    "    categories = [\"Voiga\", \"Me\", \"Keanu\", \"Rest\"]\n",
    "\n",
    "    data_gen = ImageDataGenerator(rescale=1.0 / 255, validation_split=0.2)\n",
    "\n",
    "    train_data = data_gen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode=\"categorical\",\n",
    "        subset=\"training\",\n",
    "    )\n",
    "    val_data = data_gen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode=\"categorical\",\n",
    "        subset=\"validation\",\n",
    "    )\n",
    "\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Conv2D(32, (3, 3), activation=\"relu\", input_shape=(64, 64, 3)),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(128, activation=\"relu\"),\n",
    "            Dense(len(categories), activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    model.fit(train_data, validation_data=val_data, epochs=epochs)\n",
    "\n",
    "    model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_train_save_model(\"./saved_models/model_1_e1.keras\", 1)\n",
    "create_train_save_model(\"./saved_models/model_1_e5.keras\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_1 = tf.keras.models.load_model(\"./saved_models/model_1_e1.keras\")\n",
    "test_model_2 = tf.keras.models.load_model(\"./saved_models/model_1_e5.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"./saved_models/model_1_e1.keras\")\n",
    "\n",
    "# Load the face detection model\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")\n",
    "\n",
    "# Start the webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "class_names = [\"Voiga\", \"Me\", \"Keanu\", \"Rest\"]\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    img_center_x = frame.shape[1] // 2\n",
    "    img_center_y = frame.shape[0] // 2\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        roi_color = frame[y : y + h, x : x + w]\n",
    "        roi_color_resized = cv2.resize(\n",
    "            roi_color, (64, 64)\n",
    "        )\n",
    "        roi_color_normalized = (\n",
    "            roi_color_resized / 255.0\n",
    "        )\n",
    "        roi_color_expanded = np.expand_dims(\n",
    "            roi_color_normalized, axis=0\n",
    "        )\n",
    "        predictions = model.predict(roi_color_expanded)\n",
    "        predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "        if predicted_class >= len(class_names):\n",
    "            label = \"Rest\"\n",
    "        else:\n",
    "            label = class_names[predicted_class]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        cv2.putText(\n",
    "            frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2\n",
    "        )\n",
    "\n",
    "        face_center_x = x + w // 2\n",
    "        face_center_y = y + h // 2\n",
    "\n",
    "        cv2.line(\n",
    "            frame,\n",
    "            (img_center_x, img_center_y),\n",
    "            (face_center_x, face_center_y),\n",
    "            (0, 255, 0),\n",
    "            2,\n",
    "        )\n",
    "\n",
    "        distance = np.sqrt(\n",
    "            (face_center_x - img_center_x) ** 2 + (face_center_y - img_center_y) ** 2\n",
    "        )\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            f\"Dist: {int(distance)}\",\n",
    "            (face_center_x, face_center_y),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (255, 255, 255),\n",
    "            1,\n",
    "        )\n",
    "\n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
